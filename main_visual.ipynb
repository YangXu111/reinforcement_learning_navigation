{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current device is cuda:0\n",
      "2021-02-13 19:10:49,010 INFO CUDA version: 11.0, CUDA enabled: True\n"
     ]
    }
   ],
   "source": [
    "# import IPython\n",
    "# IPython.Application.instance().kernel.do_shutdown(True) #automatically restarts kernel\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from unityagents import UnityEnvironment\n",
    "import matplotlib.pyplot as plt\n",
    "from dqn_agent import DQNAgent, ReplayMemory, device\n",
    "from double_dqn_agent import DoubleDQNAgent\n",
    "from prioritized_replay_dqn_agent import PrioritizedReplayDQNAgent, PrioritizedReplayMemory\n",
    "from dueling_dqn_agent import DuelingDQNAgent\n",
    "import sys, math, time, torch, logging, json, dill\n",
    "\n",
    "# os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "log_file_path = 'output.log'\n",
    "result_file_path = 'result.json'\n",
    "algorithm = 'DQN'\n",
    "# ['DQN','Double DQN', 'Prioritized Experience Replay', 'Dueling DQN']\n",
    "\n",
    "logger = logging.getLogger('p1_navigation_pixels')\n",
    "while logger.handlers:\n",
    "    logger.removeHandler(logger.handlers[0])\n",
    "logger.propagate = False\n",
    "\n",
    "formatter = logging.Formatter('%(asctime)s %(levelname)s %(message)s')\n",
    "\n",
    "sh = logging.StreamHandler(sys.stdout)\n",
    "sh.setFormatter(formatter)\n",
    "sh.setLevel(logging.DEBUG)\n",
    "\n",
    "fh = logging.FileHandler(log_file_path)\n",
    "fh.setLevel(logging.INFO)\n",
    "\n",
    "logger.addHandler(sh)\n",
    "logger.addHandler(fh)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "\n",
    "logger.info('CUDA version: %s, CUDA enabled: %s' % (torch.version.cuda, torch.backends.cudnn.enabled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\t\n",
      "Unity brain name: BananaBrain\n",
      "        Number of Visual Observations (per agent): 1\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 0\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: discrete\n",
      "        Vector Action space size (per agent): 4\n",
      "        Vector Action descriptions: , , , \n"
     ]
    }
   ],
   "source": [
    "env = UnityEnvironment(file_name='VisualBanana_Windows_x86_64/Banana.exe')\n",
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-02-13 19:10:54,552 DEBUG Number of agents: 1\n",
      "2021-02-13 19:10:54,554 DEBUG States look like: [[[[0.83921569 0.7254902  0.59215686]\n",
      "   [0.83921569 0.7254902  0.59215686]\n",
      "   [0.83921569 0.7254902  0.59215686]\n",
      "   ...\n",
      "   [0.83921569 0.7254902  0.59215686]\n",
      "   [0.83921569 0.7254902  0.59215686]\n",
      "   [0.83921569 0.7254902  0.59215686]]\n",
      "\n",
      "  [[0.83921569 0.7254902  0.59215686]\n",
      "   [0.83921569 0.7254902  0.59215686]\n",
      "   [0.83921569 0.7254902  0.59215686]\n",
      "   ...\n",
      "   [0.83921569 0.7254902  0.59215686]\n",
      "   [0.83921569 0.7254902  0.59215686]\n",
      "   [0.83921569 0.7254902  0.59215686]]\n",
      "\n",
      "  [[0.83921569 0.7254902  0.59215686]\n",
      "   [0.83921569 0.7254902  0.59215686]\n",
      "   [0.83921569 0.7254902  0.59215686]\n",
      "   ...\n",
      "   [0.83921569 0.7254902  0.59215686]\n",
      "   [0.83921569 0.7254902  0.59215686]\n",
      "   [0.83921569 0.7254902  0.59215686]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.39215686 0.34117647 0.2745098 ]\n",
      "   [0.39215686 0.34117647 0.2745098 ]\n",
      "   [0.39215686 0.34117647 0.2745098 ]\n",
      "   ...\n",
      "   [0.21568627 0.17647059 0.51372549]\n",
      "   [0.18039216 0.14901961 0.37254902]\n",
      "   [0.3254902  0.30588235 0.4627451 ]]\n",
      "\n",
      "  [[0.39215686 0.34117647 0.2745098 ]\n",
      "   [0.39215686 0.34117647 0.2745098 ]\n",
      "   [0.39215686 0.34117647 0.2745098 ]\n",
      "   ...\n",
      "   [0.16078431 0.1254902  0.44313725]\n",
      "   [0.15294118 0.1254902  0.3254902 ]\n",
      "   [0.33333333 0.30980392 0.44313725]]\n",
      "\n",
      "  [[0.38823529 0.3372549  0.27058824]\n",
      "   [0.38823529 0.3372549  0.27058824]\n",
      "   [0.38823529 0.3372549  0.27058824]\n",
      "   ...\n",
      "   [0.16078431 0.12941176 0.43137255]\n",
      "   [0.16078431 0.12941176 0.32156863]\n",
      "   [0.34117647 0.32156863 0.44705882]]]]\n",
      "2021-02-13 19:10:54,555 INFO Number of agents: 1, states 1, actions: 4\n",
      "2021-02-13 19:10:57,997 INFO DQN\n",
      "2021-02-13 19:10:57,999 INFO {\n",
      "    \"hidden_layer_size\": 128,\n",
      "    \"random_seed\": 2,\n",
      "    \"learning_rate\": 0.01,\n",
      "    \"tau\": 0.1,\n",
      "    \"gamma\": 0.99,\n",
      "    \"memory_size\": 1000,\n",
      "    \"update_interval\": 4,\n",
      "    \"sample_size\": 64,\n",
      "    \"num_episodes\": 6000,\n",
      "    \"epsilon_begin\": 1,\n",
      "    \"epsilon_stable\": 0.01,\n",
      "    \"epsilon_decay\": 0.9992327661102197\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# reset the environment\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "# number of agents in the environment\n",
    "logger.debug('Number of agents: %i' % len(env_info.agents))\n",
    "\n",
    "# examine the state space \n",
    "state = env_info.visual_observations[0]\n",
    "logger.debug('States look like: %s' % state)\n",
    "state_size = len(state)\n",
    "\n",
    "# number of actions\n",
    "action_size = brain.vector_action_space_size\n",
    "logger.info('Number of agents: %i, states %i, actions: %i' % (len(env_info.agents), state_size, action_size))\n",
    "\n",
    "if algorithm == 'DQN':\n",
    "    from constants import CONSTANTS as C\n",
    "    agent = DQNAgent(state_size, action_size, use_cnn_network=True)\n",
    "elif algorithm == 'Double DQN':\n",
    "    from constants import CONSTANTS as C\n",
    "    agent = DoubleDQNAgent(state_size, action_size, use_cnn_network=True)\n",
    "elif algorithm == 'Prioritized Experience Replay':\n",
    "    from constants import PRIORITIZED_REPLAY_CONSTANTS as C\n",
    "    agent = PrioritizedReplayDQNAgent(state_size, action_size, use_cnn_network=True)\n",
    "    beta = C['beta_begin']\n",
    "    logger.info('It takes %f steps for beta to go from %f to %f' % ((C['beta_stable']-C['beta_begin'])/C['beta_increase'], C['beta_begin'], C['beta_stable']))\n",
    "elif algorithm == 'Dueling DQN':\n",
    "    from constants import CONSTANTS as C\n",
    "    agent = DuelingDQNAgent(state_size, action_size, use_cnn_network=True)\n",
    "else:\n",
    "    logger.warning('No algorithm specified')\n",
    "\n",
    "logger.info(algorithm)\n",
    "logger.info(json.dumps(C, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-02-13 19:10:58,114 INFO It takes 6000.000000 steps for epsilon to go from 1.000000 to 0.010000\n"
     ]
    }
   ],
   "source": [
    "# initialize from scratch\n",
    "episode_score_hist = []\n",
    "total_score = 0\n",
    "step = 0\n",
    "epsilon = C['epsilon_begin']\n",
    "logger.info('It takes %f steps for epsilon to go from %f to %f' % (math.log(C['epsilon_stable']/C['epsilon_begin'], C['epsilon_decay']), C['epsilon_begin'], C['epsilon_stable']))\n",
    "\n",
    "# initialize from file\n",
    "# with open('parameters_1.model', 'rb') as input:\n",
    "#     checkpoint = dill.load(input)\n",
    "# with open('agent_memory_1.data', 'rb') as input:\n",
    "#     agent_memory = dill.load(input)\n",
    "    \n",
    "# agent.network.load_state_dict(checkpoint['network_state_dict'])\n",
    "# agent.target_network.load_state_dict(checkpoint['target_network_state_dict'])\n",
    "# agent.replay_memory = agent_memory\n",
    "# episode_score_hist = checkpoint['episode_score_hist']\n",
    "# total_score = checkpoint['total_score']\n",
    "# step = checkpoint['step']\n",
    "# epsilon = checkpoint['epsilon']\n",
    "# start_episode = len(episode_score_hist)\n",
    "# del checkpoint, agent_memory\n",
    "# logger.info('Starting episode: %i, Starting epsilon: %.2f, Starting memory length %i' % (start_episode, epsilon, len(agent.replay_memory.memory)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-02-13 19:10:58,251 INFO Start episode: 0\n",
      "2021-02-13 19:11:15,222 INFO For episode 0, the average score is 0.00, episode history [0.0]\n",
      "2021-02-13 19:40:01,393 INFO For episode 100, the average score is -0.03, episode history [2.0, 1.0, 1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, 3.0, -3.0, -2.0, -1.0, 0.0, 0.0, 0.0, 1.0, 0.0, -1.0, -1.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, -2.0, 0.0, -1.0, 0.0, -1.0, 1.0, -2.0, 0.0, -1.0, 1.0, -2.0, 1.0, 1.0, 2.0, 1.0, -2.0, 0.0, -1.0, 0.0, -1.0, -1.0, 0.0, 0.0, 3.0, 1.0, 0.0, -4.0, 0.0, -1.0, 0.0, 0.0, 0.0, 3.0, 0.0, -1.0, -1.0, 0.0, -1.0, -2.0, 1.0, -1.0, 0.0, 0.0, 1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, 3.0, -1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0]\n",
      "2021-02-13 20:08:48,256 INFO For episode 200, the average score is 0.16, episode history [1.0, 1.0, -1.0, -1.0, 1.0, 1.0, -1.0, -1.0, 0.0, -2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, -1.0, -2.0, 0.0, 1.0, 0.0, 0.0, 1.0, -1.0, 1.0, 0.0, 0.0, -1.0, 1.0, 0.0, -1.0, -2.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -1.0, 0.0, 1.0, -2.0, 0.0, 1.0, -1.0, -1.0, 1.0, 2.0, 0.0, -2.0, 1.0, -1.0, 1.0, -1.0, 1.0, -1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 2.0, 1.0, 0.0, -1.0, -2.0, 1.0, 1.0, 0.0, 1.0, -1.0, 3.0, 1.0, 0.0, 0.0, -1.0, 1.0, 1.0, -2.0, -1.0, 2.0, 1.0, -1.0, 2.0, 1.0, 1.0, -1.0, 1.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 4.0, 3.0]\n",
      "2021-02-13 20:37:46,502 INFO For episode 300, the average score is -0.10, episode history [0.0, 0.0, -1.0, 0.0, -1.0, -2.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0, -1.0, -2.0, 1.0, 0.0, -1.0, 0.0, 1.0, 0.0, 1.0, -1.0, 0.0, -2.0, -2.0, 1.0, 1.0, -1.0, 1.0, 1.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -1.0, -2.0, -1.0, 2.0, 0.0, 0.0, 0.0, -1.0, 0.0, 1.0, 1.0, 0.0, -2.0, 0.0, 1.0, -1.0, -2.0, 2.0, -2.0, 2.0, -1.0, -2.0, 0.0, 0.0, 0.0, 1.0, -1.0, 0.0, 1.0, 1.0, -1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 2.0, -1.0, 0.0, -2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, 2.0, 0.0, -1.0]\n",
      "2021-02-13 21:06:51,664 INFO For episode 400, the average score is 0.20, episode history [-1.0, 3.0, 1.0, 1.0, 2.0, 0.0, 1.0, 1.0, -1.0, 0.0, 1.0, 0.0, 0.0, 3.0, 0.0, 0.0, 1.0, 1.0, -1.0, 1.0, -2.0, 0.0, -1.0, 0.0, -1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, -2.0, 5.0, -1.0, -2.0, -1.0, 3.0, 0.0, 0.0, 1.0, 0.0, 1.0, -1.0, -1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 1.0, -2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, -3.0, -1.0, 1.0, 3.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 3.0, 2.0, 0.0, 0.0, 0.0, -2.0, 1.0, -3.0, -1.0, 0.0, 0.0, 2.0, 1.0, 2.0, 2.0, 0.0, 1.0, -2.0, 0.0, -1.0, -1.0, 1.0]\n",
      "2021-02-13 21:38:03,391 INFO For episode 500, the average score is 0.24, episode history [1.0, 0.0, 0.0, 1.0, 1.0, -2.0, 0.0, 1.0, 0.0, 2.0, 1.0, -2.0, -1.0, 1.0, 1.0, 0.0, 0.0, -2.0, 2.0, 1.0, 0.0, -1.0, 1.0, 0.0, -1.0, -1.0, -1.0, 0.0, 1.0, -2.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, -1.0, 2.0, 1.0, 1.0, 2.0, 2.0, 2.0, -1.0, -1.0, 1.0, 1.0, 1.0, 1.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -2.0, 2.0, 0.0, 0.0, 0.0, -1.0, -1.0, -2.0, -4.0, 3.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 3.0, 0.0, 1.0, 1.0, -1.0, 3.0, -1.0, 0.0, 1.0, -1.0, 1.0, 1.0, 1.0, 0.0, -1.0, 1.0, -1.0, 2.0, 1.0, 0.0, -1.0, 2.0, 3.0, -1.0, 1.0, -2.0]\n",
      "2021-02-13 22:15:17,964 INFO For episode 600, the average score is 0.27, episode history [0.0, 1.0, 1.0, 1.0, 2.0, -3.0, -4.0, -1.0, 0.0, 1.0, 2.0, 0.0, -2.0, -1.0, -5.0, 0.0, 0.0, 3.0, 0.0, -1.0, -1.0, 0.0, 1.0, -1.0, 0.0, -1.0, -1.0, -1.0, 0.0, 0.0, 2.0, -1.0, 0.0, 4.0, 0.0, -2.0, 0.0, 1.0, 0.0, 2.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 3.0, 3.0, 0.0, -1.0, 1.0, 1.0, 0.0, 0.0, 1.0, -1.0, 1.0, -1.0, 1.0, 0.0, 0.0, 0.0, 1.0, -1.0, 1.0, -1.0, 0.0, 5.0, 2.0, 1.0, -1.0, 0.0, 1.0, 0.0, -1.0, 0.0, 0.0, 2.0, 1.0, -1.0, 0.0, -1.0, 2.0, 2.0, -2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0, 1.0, 1.0, 0.0, 3.0, 2.0, 0.0, -3.0]\n",
      "2021-02-13 22:52:35,485 INFO For episode 700, the average score is 0.03, episode history [1.0, -1.0, 1.0, 3.0, 2.0, 1.0, 0.0, 1.0, -2.0, 0.0, -1.0, -1.0, 3.0, 0.0, 2.0, 0.0, 0.0, -1.0, 0.0, 0.0, 3.0, -2.0, 0.0, -1.0, -2.0, -1.0, 1.0, -1.0, 0.0, -1.0, 0.0, 0.0, 0.0, 3.0, -1.0, 0.0, 0.0, 1.0, -3.0, 2.0, -1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 2.0, -1.0, 0.0, -1.0, 0.0, 0.0, 1.0, 0.0, 1.0, -1.0, 1.0, 0.0, -1.0, 0.0, 0.0, -1.0, -1.0, 0.0, -1.0, -1.0, 2.0, -1.0, 0.0, 1.0, 0.0, 1.0, -1.0, 0.0, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, -1.0, 1.0, 0.0, 1.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, 0.0, 0.0, 0.0, -1.0, 1.0]\n",
      "2021-02-13 23:29:56,271 INFO For episode 800, the average score is 0.13, episode history [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 2.0, 1.0, -2.0, 0.0, 1.0, 2.0, -1.0, -2.0, 0.0, 2.0, -2.0, -1.0, 0.0, -2.0, 1.0, -2.0, 1.0, 0.0, -1.0, 0.0, 2.0, 1.0, 1.0, 3.0, 2.0, -1.0, -3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 5.0, -1.0, -1.0, -5.0, 1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 1.0, -1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 0.0, -1.0, -1.0, -2.0, 4.0, 0.0, 1.0, 0.0, 0.0, 1.0, -1.0, 0.0, 1.0, 1.0, -2.0, 0.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, -2.0, -1.0, 2.0, 2.0, 1.0, -1.0, -1.0, -4.0, 0.0, 0.0, 0.0]\n",
      "2021-02-14 00:00:36,939 INFO For episode 900, the average score is 0.14, episode history [-1.0, -1.0, 2.0, 1.0, 1.0, 1.0, 0.0, 2.0, -2.0, 2.0, -1.0, 0.0, 3.0, 1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, 0.0, 1.0, 2.0, 1.0, -1.0, 1.0, 2.0, 1.0, 1.0, -2.0, 3.0, 0.0, 3.0, -4.0, 1.0, 0.0, 1.0, -1.0, -1.0, 0.0, -2.0, -1.0, -1.0, 0.0, 0.0, -3.0, 1.0, 0.0, 1.0, 0.0, -2.0, 0.0, 1.0, 2.0, -3.0, 0.0, -1.0, 1.0, 3.0, 0.0, 1.0, -1.0, -1.0, 0.0, 0.0, 1.0, 1.0, -2.0, 1.0, 0.0, 1.0, -1.0, 0.0, -1.0, 0.0, 2.0, -1.0, 1.0, 0.0, 1.0, -1.0, -2.0, 2.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, -2.0, 0.0, -1.0, 0.0]\n",
      "2021-02-14 00:31:17,113 INFO For episode 1000, the average score is 0.27, episode history [-3.0, -1.0, 1.0, -2.0, -1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 1.0, -1.0, 0.0, 1.0, -1.0, 0.0, -1.0, 1.0, 1.0, 1.0, 0.0, -1.0, 1.0, 2.0, -1.0, 0.0, 3.0, 2.0, 1.0, 1.0, -1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, -1.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 2.0, 2.0, -1.0, 1.0, 0.0, 1.0, -1.0, 1.0, -3.0, 1.0, 2.0, -2.0, -1.0, 0.0, 2.0, 3.0, 1.0, 1.0, -1.0, 0.0, 3.0, 0.0, 1.0, 1.0, 0.0, 2.0, 0.0, 1.0, 1.0, -1.0, -1.0, -1.0, 2.0, -4.0, 1.0, 1.0, 2.0, -1.0, 0.0, 1.0, 1.0, 1.0, 0.0, -1.0, 0.0, 0.0]\n",
      "2021-02-14 01:01:26,987 INFO For episode 1100, the average score is 0.43, episode history [0.0, 1.0, -2.0, 1.0, 4.0, 2.0, -1.0, 4.0, 2.0, -1.0, 2.0, 1.0, 1.0, 1.0, 2.0, 0.0, 0.0, 1.0, -1.0, 0.0, -1.0, -2.0, 1.0, 2.0, 0.0, 0.0, 1.0, -1.0, -3.0, -1.0, 3.0, 1.0, -2.0, 0.0, 0.0, 1.0, 3.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 2.0, 1.0, 0.0, 3.0, 4.0, -2.0, -4.0, 2.0, 0.0, 1.0, 0.0, -1.0, 2.0, 1.0, 0.0, 1.0, 0.0, -1.0, -1.0, 0.0, -2.0, 0.0, 1.0, 3.0, -2.0, 1.0, 2.0, -2.0, 3.0, -1.0, 1.0, 0.0, 2.0, -1.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, -2.0, -2.0, 1.0, 1.0, 0.0, 0.0]\n",
      "2021-02-14 01:31:06,590 INFO For episode 1200, the average score is 0.56, episode history [2.0, 2.0, 1.0, 3.0, 1.0, 0.0, 1.0, 0.0, 3.0, 2.0, 1.0, 1.0, 0.0, -1.0, 0.0, 1.0, -3.0, -1.0, 0.0, 2.0, 3.0, 0.0, 2.0, 0.0, 0.0, 1.0, -1.0, 3.0, 0.0, 1.0, 0.0, 0.0, 1.0, 3.0, 0.0, 3.0, 2.0, -1.0, -4.0, 2.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 1.0, -1.0, 2.0, 0.0, -1.0, 0.0, 0.0, 2.0, 1.0, 0.0, 1.0, -1.0, 2.0, 1.0, 0.0, 0.0, 0.0, 3.0, 0.0, -1.0, 1.0, 1.0, 0.0, -1.0, -2.0, 2.0, 1.0, -1.0, 0.0, 0.0, 1.0, -1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 2.0, 3.0, 1.0, 1.0, 0.0, 0.0, 2.0, 1.0, -2.0, 0.0]\n",
      "2021-02-14 02:00:47,736 INFO For episode 1300, the average score is 0.89, episode history [-1.0, -2.0, 0.0, 3.0, 2.0, 2.0, 0.0, -1.0, 1.0, 3.0, 2.0, -1.0, 4.0, 2.0, 1.0, 2.0, 2.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 3.0, -1.0, -1.0, 0.0, 2.0, 0.0, 1.0, 3.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 1.0, 2.0, 3.0, 0.0, 0.0, 0.0, 1.0, -1.0, 1.0, 0.0, 0.0, 2.0, 0.0, -2.0, -1.0, 0.0, 1.0, 5.0, 0.0, 1.0, 2.0, 1.0, 1.0, 3.0, 1.0, 1.0, 1.0, -1.0, -1.0, -1.0, 3.0, 0.0, 3.0, 3.0, 0.0, -1.0, 1.0, 0.0, 0.0, 0.0, 3.0, 1.0, 2.0, 0.0, 3.0, 2.0, 0.0, 2.0, 5.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 1.0, -1.0, 3.0, 0.0, 3.0]\n",
      "2021-02-14 02:30:27,630 INFO For episode 1400, the average score is 0.69, episode history [1.0, 5.0, -3.0, 0.0, -1.0, 3.0, -2.0, -4.0, 0.0, 1.0, 0.0, 3.0, 1.0, 0.0, 4.0, 2.0, 0.0, 0.0, 0.0, -1.0, -2.0, 0.0, -1.0, 1.0, 1.0, 3.0, 1.0, -3.0, 1.0, -3.0, -1.0, 2.0, 0.0, 4.0, 7.0, 1.0, 0.0, 1.0, -2.0, 3.0, 0.0, -1.0, 2.0, 2.0, 1.0, 1.0, -2.0, 3.0, 2.0, 3.0, 1.0, 4.0, 0.0, -1.0, 1.0, 2.0, 3.0, 4.0, 3.0, 0.0, 1.0, -1.0, -1.0, 0.0, 1.0, 2.0, 1.0, 3.0, 0.0, -1.0, 0.0, 0.0, 1.0, 3.0, 4.0, -2.0, 0.0, 0.0, 2.0, 1.0, 0.0, 3.0, 0.0, -1.0, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, 1.0, -1.0, 3.0, 0.0, 1.0, 0.0, -1.0, -1.0, 3.0, 0.0]\n",
      "2021-02-14 03:00:16,751 INFO For episode 1500, the average score is 1.01, episode history [0.0, 1.0, 1.0, -1.0, 0.0, 0.0, 3.0, 3.0, 3.0, 1.0, 4.0, 2.0, 2.0, -1.0, 0.0, 0.0, 5.0, -2.0, 2.0, 2.0, 4.0, 0.0, 3.0, 3.0, 3.0, 4.0, -1.0, 5.0, 6.0, -2.0, 1.0, 0.0, 3.0, 1.0, 1.0, 0.0, -3.0, 1.0, 0.0, 2.0, 0.0, -2.0, 3.0, 3.0, 1.0, 1.0, 2.0, 3.0, 0.0, 1.0, 0.0, -3.0, 2.0, 1.0, 0.0, 1.0, 0.0, 3.0, 3.0, 1.0, -1.0, 0.0, 1.0, -2.0, -1.0, 1.0, 0.0, 1.0, 5.0, 3.0, 0.0, 0.0, 0.0, 4.0, -1.0, -1.0, 2.0, 5.0, 2.0, 1.0, 2.0, 3.0, 0.0, -1.0, 4.0, 0.0, -1.0, -2.0, 2.0, -2.0, 1.0, -1.0, -2.0, 1.0, 2.0, 0.0, -1.0, 2.0, 0.0, -1.0]\n",
      "2021-02-14 03:30:08,993 INFO For episode 1600, the average score is 0.51, episode history [3.0, 6.0, -2.0, 0.0, 4.0, -2.0, -2.0, 0.0, 0.0, -1.0, 1.0, 0.0, 1.0, -1.0, 1.0, 0.0, 0.0, 0.0, -1.0, -1.0, -2.0, 0.0, 2.0, 2.0, -1.0, 0.0, 0.0, -2.0, 0.0, -1.0, 5.0, 5.0, -1.0, 1.0, -1.0, 1.0, -1.0, 0.0, 3.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, -1.0, -2.0, 2.0, -1.0, 0.0, 2.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, -1.0, 2.0, -1.0, 5.0, 1.0, -2.0, 1.0, 0.0, 1.0, 2.0, 1.0, 2.0, 2.0, 1.0, -3.0, 2.0, -2.0, 2.0, -1.0, 0.0, -1.0, 0.0, 0.0, 1.0, -1.0, 2.0, 5.0, -1.0, -3.0, 0.0, 1.0, 1.0, 0.0, 5.0, 2.0, 6.0]\n",
      "2021-02-14 03:59:57,572 INFO For episode 1700, the average score is 0.72, episode history [-1.0, 0.0, 2.0, 1.0, 2.0, 2.0, 0.0, -2.0, 2.0, 2.0, 0.0, -2.0, -1.0, 0.0, 0.0, -1.0, 0.0, 2.0, 2.0, 1.0, -1.0, 1.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 1.0, 2.0, 2.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, -1.0, 0.0, 1.0, 2.0, 1.0, 0.0, 3.0, 0.0, 0.0, 1.0, 6.0, 2.0, 2.0, 0.0, 0.0, 2.0, 1.0, 1.0, -1.0, 2.0, 0.0, 1.0, 1.0, -1.0, -1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 0.0, 1.0, 3.0, 0.0, 1.0, -1.0, -2.0, 2.0, 0.0, -1.0, 1.0, 0.0, 1.0, -1.0, 4.0, 8.0, 2.0, -2.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, -1.0, 1.0, 2.0, 3.0, 1.0]\n",
      "2021-02-14 04:29:52,002 INFO For episode 1800, the average score is 1.07, episode history [-1.0, 1.0, 2.0, 0.0, 1.0, 2.0, 1.0, 2.0, -2.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.0, -1.0, 0.0, 3.0, -2.0, 3.0, -3.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 2.0, 4.0, -1.0, 2.0, 1.0, 1.0, 1.0, 0.0, 1.0, 2.0, 0.0, 1.0, 2.0, 1.0, 2.0, 3.0, -1.0, 1.0, 1.0, -1.0, -1.0, 1.0, 0.0, -1.0, -1.0, 1.0, 0.0, -1.0, 0.0, 3.0, -2.0, 0.0, 1.0, 3.0, -1.0, 6.0, 1.0, 2.0, 1.0, 2.0, 3.0, 4.0, 2.0, 1.0, 1.0, 0.0, 4.0, 0.0, 3.0, 2.0, 4.0, 6.0, 2.0, 4.0, 2.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 4.0, 2.0, 1.0, -1.0, 1.0, 1.0, 4.0, 0.0, 1.0]\n",
      "2021-02-14 04:59:55,187 INFO For episode 1900, the average score is 1.02, episode history [2.0, 1.0, 0.0, 1.0, -2.0, 2.0, 0.0, 1.0, -1.0, 3.0, -1.0, 1.0, -2.0, 0.0, 0.0, 2.0, 2.0, 1.0, 5.0, 1.0, -2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 5.0, 4.0, 1.0, 0.0, 3.0, 3.0, 4.0, -1.0, 0.0, 5.0, 0.0, 1.0, 1.0, -1.0, 1.0, 1.0, 5.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, -3.0, 0.0, 2.0, 2.0, -1.0, 3.0, 1.0, 1.0, 2.0, 0.0, 4.0, -1.0, 1.0, 4.0, -1.0, -2.0, 1.0, 3.0, 7.0, 0.0, 2.0, 3.0, 0.0, 4.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, -1.0, 2.0, 3.0, 2.0, -1.0, 1.0, -1.0, 0.0, 3.0, -2.0, -2.0, -1.0, 7.0, 6.0, 0.0]\n",
      "2021-02-14 05:29:58,811 INFO For episode 2000, the average score is 1.06, episode history [-2.0, 0.0, 1.0, 1.0, 2.0, 2.0, 1.0, 4.0, -2.0, 1.0, 1.0, 4.0, 2.0, 2.0, -1.0, 0.0, -1.0, 0.0, 0.0, 1.0, -1.0, 0.0, -1.0, -2.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 4.0, 5.0, 0.0, 1.0, 0.0, 7.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 2.0, 3.0, 3.0, 1.0, 3.0, 0.0, 6.0, 2.0, 0.0, 0.0, 0.0, 0.0, 3.0, 3.0, 0.0, 3.0, 1.0, 4.0, 0.0, 0.0, 1.0, 1.0, 2.0, 2.0, -1.0, 7.0, 3.0, 2.0, 2.0, 1.0, 4.0, 1.0, 0.0, 0.0, 0.0, 2.0, -2.0, -2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 3.0, -2.0, -2.0, 3.0, 0.0, 1.0, 2.0]\n",
      "2021-02-14 05:59:56,396 INFO For episode 2100, the average score is 1.53, episode history [1.0, 0.0, 0.0, 5.0, 0.0, -2.0, -1.0, 1.0, 4.0, 2.0, 1.0, 1.0, 0.0, 1.0, 3.0, 0.0, -1.0, 0.0, 1.0, -1.0, 0.0, 1.0, 6.0, 2.0, -1.0, 2.0, 1.0, 1.0, 5.0, 5.0, 2.0, 5.0, 2.0, 0.0, 3.0, -1.0, 3.0, 0.0, 3.0, 2.0, 2.0, -2.0, 7.0, -1.0, 1.0, 3.0, 2.0, -1.0, 5.0, 3.0, 0.0, 5.0, 4.0, 0.0, 3.0, 2.0, 0.0, 1.0, 1.0, 0.0, 2.0, 2.0, 2.0, 4.0, 1.0, 0.0, 2.0, 1.0, 2.0, 0.0, 4.0, -1.0, 2.0, 2.0, -1.0, 3.0, 3.0, 1.0, 1.0, 2.0, 4.0, 1.0, 3.0, -1.0, 4.0, -2.0, 1.0, 1.0, 0.0, -1.0, 2.0, 3.0, 5.0, 9.0, 2.0, 2.0, 0.0, -1.0, 0.0, -2.0]\n",
      "2021-02-14 06:29:54,819 INFO For episode 2200, the average score is 1.44, episode history [0.0, 0.0, -2.0, 4.0, 1.0, 1.0, 0.0, -2.0, 2.0, 2.0, -1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 0.0, 0.0, 4.0, 1.0, -1.0, 2.0, 1.0, -1.0, 0.0, 2.0, 0.0, -1.0, 0.0, 0.0, -2.0, 0.0, -1.0, 0.0, 0.0, -3.0, 3.0, 2.0, 2.0, 4.0, 0.0, 3.0, 0.0, 5.0, -1.0, 3.0, 1.0, 0.0, 4.0, 0.0, 4.0, 1.0, -1.0, 1.0, 2.0, 0.0, 6.0, 3.0, 1.0, -2.0, 3.0, 1.0, 2.0, 3.0, 3.0, 1.0, 0.0, 5.0, 8.0, 0.0, 4.0, 4.0, 3.0, 1.0, 0.0, 3.0, 1.0, 1.0, 4.0, 1.0, 1.0, 7.0, 3.0, 2.0, 0.0, 3.0, 1.0, 2.0, 3.0, 2.0, 0.0, 3.0, 4.0, 4.0, 2.0, 2.0, 0.0, -2.0, 4.0]\n",
      "2021-02-14 06:59:56,693 INFO For episode 2300, the average score is 1.94, episode history [5.0, 3.0, 1.0, 1.0, 0.0, -1.0, -2.0, 5.0, 6.0, 9.0, 1.0, 5.0, 2.0, 2.0, 4.0, 0.0, 5.0, 3.0, -3.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, -1.0, -2.0, 4.0, 4.0, 2.0, 2.0, 5.0, -1.0, 2.0, 3.0, 5.0, 3.0, 1.0, 1.0, 1.0, 1.0, -1.0, 0.0, 1.0, 1.0, 1.0, -2.0, 1.0, 0.0, 1.0, 2.0, 1.0, 0.0, 3.0, 7.0, 1.0, 2.0, 5.0, 6.0, 3.0, 0.0, 6.0, 5.0, 4.0, 4.0, 1.0, -2.0, 5.0, 2.0, 2.0, 4.0, 1.0, -3.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 4.0, -1.0, 0.0, 3.0, 5.0, 1.0, 2.0, 2.0, 3.0, 1.0, 0.0, 4.0, 2.0, 2.0, 1.0, 9.0, 1.0, -1.0, 3.0, 0.0, 3.0]\n",
      "2021-02-14 07:29:59,620 INFO For episode 2400, the average score is 1.97, episode history [2.0, -1.0, 4.0, 1.0, 4.0, 2.0, 2.0, 5.0, 5.0, 4.0, 1.0, 4.0, 3.0, 6.0, 2.0, 0.0, 1.0, 2.0, 2.0, 6.0, 4.0, 0.0, 4.0, 1.0, 0.0, 5.0, 2.0, 3.0, 5.0, -1.0, 0.0, 4.0, 5.0, 0.0, 1.0, 4.0, 4.0, 0.0, 0.0, 3.0, 6.0, 1.0, 3.0, 1.0, 2.0, 5.0, 0.0, 6.0, 5.0, -1.0, 1.0, -3.0, 0.0, 1.0, 1.0, -1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 2.0, -1.0, 6.0, 0.0, 2.0, 1.0, 0.0, 3.0, 1.0, 7.0, 2.0, 0.0, 0.0, -2.0, 4.0, 4.0, -1.0, 2.0, -1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.0, 0.0, 2.0, 5.0, 2.0, 2.0, 5.0, 4.0, 1.0, 3.0, 5.0, 0.0]\n",
      "2021-02-14 08:00:03,538 INFO For episode 2500, the average score is 1.48, episode history [-1.0, 0.0, 4.0, 1.0, -1.0, 3.0, 0.0, 0.0, -1.0, 3.0, 0.0, 3.0, -1.0, -3.0, 4.0, 1.0, -2.0, 8.0, 1.0, 3.0, -2.0, 7.0, 7.0, -2.0, 1.0, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 2.0, -1.0, 4.0, 9.0, 6.0, 2.0, 4.0, 3.0, 2.0, 0.0, 6.0, 3.0, -1.0, 2.0, -1.0, 1.0, 2.0, 0.0, 0.0, -1.0, 2.0, 6.0, 3.0, 3.0, 4.0, 0.0, 1.0, 1.0, -3.0, 0.0, 4.0, 2.0, 4.0, 1.0, 2.0, 3.0, 4.0, -4.0, 1.0, 2.0, 4.0, 2.0, 2.0, -2.0, 3.0, 2.0, 1.0, 0.0, 1.0, 0.0, 2.0, 3.0, 4.0, 3.0, 2.0, -1.0, -3.0, 0.0, 2.0, 1.0, 0.0, 4.0, 3.0, 1.0, 2.0, 0.0, 0.0, 2.0, 1.0]\n",
      "2021-02-14 08:30:09,444 INFO For episode 2600, the average score is 1.91, episode history [1.0, 1.0, -1.0, 0.0, 0.0, 1.0, -3.0, 0.0, 6.0, 4.0, 2.0, -2.0, 1.0, 1.0, 4.0, 1.0, 1.0, 5.0, 3.0, 2.0, 4.0, -1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 5.0, 1.0, 3.0, 1.0, 2.0, 0.0, 2.0, 6.0, 4.0, 11.0, 3.0, 0.0, 3.0, 5.0, 5.0, 4.0, 1.0, 5.0, 5.0, 2.0, -1.0, 2.0, 2.0, 2.0, 4.0, 1.0, -1.0, 1.0, 2.0, 7.0, 8.0, 5.0, 2.0, 4.0, 3.0, 3.0, 0.0, 3.0, -1.0, 3.0, 3.0, 1.0, 3.0, 4.0, -2.0, 2.0, 1.0, 4.0, 3.0, 2.0, 1.0, 2.0, 1.0, -3.0, 1.0, 6.0, 1.0, 2.0, 1.0, 2.0, 2.0, 1.0, -1.0, 1.0, 2.0, 2.0, 0.0, 1.0, 0.0, 0.0, -2.0, 1.0, 0.0]\n",
      "2021-02-14 09:00:17,764 INFO For episode 2700, the average score is 2.01, episode history [0.0, 0.0, 2.0, 2.0, 1.0, 2.0, 1.0, 6.0, -2.0, 3.0, 5.0, 2.0, 3.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 1.0, -3.0, 4.0, 3.0, 3.0, 6.0, 0.0, 2.0, 0.0, -1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, -1.0, 0.0, 2.0, 3.0, -1.0, 0.0, 3.0, 3.0, 1.0, 8.0, 1.0, 1.0, 3.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 5.0, 4.0, 11.0, 1.0, 3.0, 1.0, 1.0, 5.0, 3.0, 5.0, 1.0, 6.0, 1.0, 4.0, 3.0, 4.0, 3.0, 2.0, 3.0, 4.0, 1.0, 4.0, 2.0, -1.0, 0.0, 3.0, 3.0, 5.0, 2.0, 6.0, 1.0, 1.0, 4.0, 4.0, 4.0, 6.0, 8.0]\n",
      "2021-02-14 09:30:26,847 INFO For episode 2800, the average score is 3.07, episode history [3.0, 1.0, 3.0, 1.0, 2.0, 3.0, 1.0, 4.0, 4.0, 3.0, 5.0, 2.0, 1.0, -1.0, 1.0, 4.0, 1.0, 4.0, -1.0, 1.0, 3.0, 2.0, 6.0, 5.0, 4.0, 4.0, 3.0, 2.0, 2.0, 5.0, 0.0, 3.0, 8.0, 8.0, 2.0, 1.0, 2.0, 5.0, 8.0, 2.0, 1.0, 1.0, 1.0, 1.0, 3.0, 3.0, 2.0, 1.0, 1.0, 3.0, 3.0, 4.0, 2.0, 5.0, 4.0, 1.0, 6.0, 2.0, 4.0, 5.0, 5.0, 3.0, 5.0, 7.0, 2.0, 2.0, 4.0, 4.0, 7.0, 1.0, 10.0, 6.0, -1.0, 6.0, 0.0, 2.0, 3.0, 3.0, 3.0, 2.0, 3.0, 2.0, 10.0, 6.0, 4.0, 1.0, 3.0, 0.0, 4.0, 5.0, 3.0, 3.0, 2.0, 4.0, 1.0, 4.0, 0.0, 1.0, 5.0, 2.0]\n",
      "2021-02-14 10:00:36,336 INFO For episode 2900, the average score is 3.14, episode history [2.0, 2.0, 2.0, 5.0, -1.0, 7.0, 4.0, 4.0, 8.0, 5.0, 2.0, -2.0, 2.0, 2.0, 3.0, 5.0, 5.0, 2.0, 2.0, 3.0, 3.0, 0.0, 0.0, 3.0, 1.0, 1.0, 8.0, 6.0, 6.0, 3.0, 6.0, 6.0, 1.0, 1.0, 1.0, 2.0, 6.0, 8.0, 3.0, 5.0, -1.0, 1.0, 2.0, 7.0, 0.0, 6.0, 2.0, 2.0, -1.0, 6.0, 3.0, 4.0, 4.0, 3.0, 6.0, -1.0, 5.0, 5.0, 4.0, 4.0, 5.0, 2.0, 6.0, 3.0, 7.0, 6.0, 8.0, 3.0, 0.0, 8.0, 7.0, 2.0, 2.0, 1.0, 5.0, 5.0, 2.0, 6.0, 0.0, 2.0, 1.0, -2.0, -1.0, 2.0, 5.0, 1.0, 0.0, 4.0, 3.0, 2.0, 7.0, 2.0, 4.0, 1.0, 1.0, 1.0, 1.0, 4.0, 2.0, 3.0]\n",
      "2021-02-14 10:30:49,371 INFO For episode 3000, the average score is 3.65, episode history [0.0, 1.0, -2.0, 3.0, 2.0, 1.0, 2.0, 4.0, 3.0, 2.0, 1.0, 2.0, 8.0, 8.0, 5.0, 5.0, 4.0, -1.0, 1.0, 2.0, 5.0, 3.0, 0.0, 8.0, 2.0, 5.0, 3.0, 4.0, 2.0, 10.0, 6.0, 1.0, 2.0, 2.0, 6.0, 3.0, 6.0, 3.0, 5.0, 1.0, 6.0, 8.0, 2.0, 3.0, 6.0, 6.0, 2.0, 7.0, 4.0, 4.0, 3.0, 2.0, 4.0, 3.0, 9.0, 0.0, 3.0, 3.0, 3.0, 1.0, 6.0, 0.0, 3.0, 3.0, 2.0, 4.0, 4.0, 0.0, 3.0, 4.0, 10.0, 3.0, 6.0, 5.0, 8.0, 4.0, 0.0, 2.0, 4.0, 4.0, 0.0, 2.0, 5.0, 3.0, 8.0, 7.0, 11.0, 2.0, 6.0, 5.0, 7.0, 8.0, 6.0, 0.0, 4.0, 3.0, 0.0, 1.0, 2.0, 3.0]\n",
      "2021-02-14 11:01:01,875 INFO For episode 3100, the average score is 3.21, episode history [2.0, 6.0, -2.0, 5.0, 4.0, 6.0, 0.0, 1.0, 3.0, 4.0, 8.0, 4.0, 7.0, 6.0, 6.0, 2.0, 7.0, 8.0, 6.0, 12.0, 6.0, 6.0, 9.0, 5.0, 2.0, 3.0, -1.0, 2.0, 0.0, 3.0, 0.0, 9.0, 3.0, 2.0, -1.0, 7.0, 5.0, 7.0, 5.0, 1.0, 1.0, 2.0, 2.0, 5.0, 4.0, 2.0, 0.0, -2.0, 5.0, 4.0, 3.0, 1.0, 1.0, 4.0, 3.0, 4.0, 2.0, 4.0, 2.0, 1.0, -1.0, 4.0, 0.0, 0.0, 1.0, 4.0, 5.0, 2.0, 0.0, 2.0, 0.0, -2.0, 1.0, 2.0, -2.0, 2.0, 1.0, 7.0, 7.0, 7.0, 3.0, 1.0, 7.0, 6.0, 5.0, 1.0, 2.0, 2.0, 6.0, 3.0, 7.0, 4.0, 2.0, 2.0, 5.0, 1.0, 1.0, 2.0, 3.0, 2.0]\n",
      "2021-02-14 11:31:35,379 INFO For episode 3200, the average score is 0.98, episode history [3.0, 1.0, 3.0, 1.0, 4.0, 2.0, 0.0, -1.0, 3.0, 0.0, -1.0, -1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, 1.0, -2.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -2.0, -1.0, -1.0, 0.0, -1.0, 1.0, 1.0, 3.0, 0.0, -1.0, -1.0, -2.0, 1.0, 2.0, 1.0, 1.0, 3.0, 0.0, 1.0, -2.0, 1.0, 0.0, 0.0, 7.0, -1.0, 6.0, 1.0, 1.0, 2.0, 2.0, -2.0, 4.0, 2.0, -1.0, 4.0, 4.0, 1.0, 0.0, -1.0, 1.0, -2.0, 2.0, 2.0, 2.0, 1.0, 0.0, 1.0, 1.0, 3.0, 5.0, 5.0, 3.0, 11.0, 3.0, 4.0, 3.0, 1.0, 1.0, 3.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0]\n",
      "2021-02-14 12:02:12,974 INFO For episode 3300, the average score is 1.36, episode history [-1.0, -1.0, 0.0, 0.0, 0.0, -1.0, 3.0, 1.0, 1.0, 0.0, 1.0, 2.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 1.0, 5.0, 2.0, 1.0, 1.0, 1.0, 0.0, 2.0, -2.0, 1.0, -1.0, 2.0, 1.0, 6.0, -2.0, 2.0, 0.0, 1.0, 1.0, 1.0, 8.0, 1.0, 2.0, 3.0, 4.0, 0.0, 4.0, 6.0, 3.0, 2.0, 1.0, 1.0, 1.0, -1.0, -1.0, -1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, -1.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 1.0, 1.0, -1.0, 1.0, -2.0, 1.0, 0.0, 0.0, 4.0, 1.0, 3.0, 1.0, 1.0, 3.0, 6.0, 5.0, 7.0, 5.0, 3.0, 5.0, 2.0, 2.0, 2.0, 3.0, 1.0, 2.0, -1.0, 1.0, 0.0, 2.0, 1.0, 6.0]\n",
      "2021-02-14 12:32:47,159 INFO For episode 3400, the average score is 2.52, episode history [-1.0, 4.0, 4.0, 9.0, 2.0, 3.0, 2.0, 0.0, 2.0, 0.0, 7.0, 5.0, 2.0, 1.0, 6.0, 2.0, 6.0, -1.0, 0.0, 1.0, 6.0, 1.0, -1.0, 2.0, 1.0, 6.0, 2.0, 5.0, 4.0, 0.0, 1.0, 1.0, 0.0, 2.0, 2.0, 3.0, 0.0, 4.0, 2.0, 9.0, 2.0, 4.0, 4.0, 3.0, 4.0, 4.0, 2.0, 3.0, 2.0, 0.0, 2.0, -2.0, 3.0, -2.0, 1.0, 3.0, 1.0, 3.0, -1.0, 3.0, 2.0, 8.0, 4.0, 1.0, 5.0, 1.0, 2.0, 0.0, 1.0, 0.0, 1.0, 2.0, 3.0, 0.0, 0.0, 3.0, -3.0, 1.0, 2.0, 2.0, 1.0, 4.0, 4.0, -1.0, 4.0, 0.0, 0.0, 6.0, 3.0, 4.0, 7.0, 3.0, 7.0, 1.0, 3.0, 10.0, 4.0, 7.0, 1.0, 6.0]\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "start_episode = len(episode_score_hist)\n",
    "logger.info('Start episode: %i' % start_episode)\n",
    "for i in range(start_episode, start_episode + C['num_episodes'] + 1):\n",
    "    env_info = env.reset(train_mode=True)[brain_name]  # reset the env at each episode\n",
    "    state = agent.preprocessing(env_info.visual_observations[0])\n",
    "    done = False\n",
    "    episode_score = 0                                  # initialize the score\n",
    "    while not done:\n",
    "        if algorithm == 'Prioritized Experience Replay':\n",
    "            action = agent.action(state, epsilon=epsilon, beta=beta)          # select an action\n",
    "            beta = min(beta+C['beta_increase'], C['beta_stable'])\n",
    "        else:\n",
    "            action = agent.action(state, epsilon=epsilon)\n",
    "        env_info = env.step(action)[brain_name]        # send the action to the environment\n",
    "        next_state = agent.preprocessing(env_info.visual_observations[0])   # get the next state\n",
    "        reward = env_info.rewards[0]                   # get the reward\n",
    "        done = env_info.local_done[0]                  # see if episode has finished\n",
    "        agent.replay_memory.add(state, action, reward, next_state, done)\n",
    "        step += 1\n",
    "#         logger.info('step, action, reward:%i, %i, %i' % (step, action, reward))\n",
    "        episode_score += reward                        # update the score\n",
    "        state = next_state                             # roll over the state to next time step\n",
    "    total_score += episode_score\n",
    "    episode_score_hist.append(episode_score)\n",
    "    epsilon = max(epsilon*C['epsilon_decay'], C['epsilon_stable'])\n",
    "    if i % 100 == 0:\n",
    "        logger.info('For episode %i, the average score is %.2f, episode history %s' % (i, total_score/100, episode_score_hist[-100:]))\n",
    "        total_score = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info('The training completes in %f mins' % ((time.time() - start_time)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = {\n",
    "    'step': step,\n",
    "    'episode_score_hist': episode_score_hist,\n",
    "    'total_score': total_score,\n",
    "    'epsilon': epsilon,\n",
    "    'network_state_dict': agent.network.state_dict(),\n",
    "    'target_network_state_dict': agent.target_network.state_dict()\n",
    "}\n",
    "with open('parameters_2.model', 'wb') as output:\n",
    "    dill.dump(checkpoint, output)\n",
    "with open('agent_memory_2.data', 'wb') as output:\n",
    "    dill.dump(agent.replay_memory, output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 10))\n",
    "plt.plot(episode_score_hist)\n",
    "plt.title('Episode Score with %s' % algorithm)\n",
    "plt.xlabel('Episodes')\n",
    "plt.ylabel('Scores')\n",
    "plt.savefig('episode_score_with_%s_visual_2.png' % algorithm, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "C['agent'] = type(agent).__name__\n",
    "C['episode_score_hist'] = episode_score_hist\n",
    "with open(result_file_path, 'a', encoding='utf-8') as f:\n",
    "    json.dump(C, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "env_info = env.reset(train_mode=False)[brain_name] # reset the environment\n",
    "state = torch.tensor(env_info.visual_observations[0]).to(device).transpose(0, 3).float().squeeze().unsqueeze(0)            # get the current state\n",
    "score = 0                                          # initialize the score\n",
    "while True:\n",
    "    action = agent.action(state, epsilon=epsilon, beta=0)                   # select an action\n",
    "    env_info = env.step(action)[brain_name]        # send the action to the environment\n",
    "    next_state = torch.tensor(env_info.visual_observations[0]).to(device).transpose(0, 3).float().squeeze().unsqueeze(0)   # get the next state\n",
    "    reward = env_info.rewards[0]                   # get the reward\n",
    "    done = env_info.local_done[0]                  # see if episode has finished\n",
    "    score += reward                                # update the score\n",
    "    state = next_state                             # roll over the state to next time step\n",
    "    if done:                                       # exit loop if episode finished\n",
    "        break\n",
    "    \n",
    "logger.info(\"Score: {}\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import gc\n",
    "# gc.collect()\n",
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.cuda.memory_summary(device=None, abbreviated=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drlnd1",
   "language": "python",
   "name": "drlnd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
